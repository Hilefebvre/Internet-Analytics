{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *F*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Dessimoz Frank*\n",
    "* *Micheli Vincent*\n",
    "* *Lefebvre Hippolyte*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from utils import load_pkl, load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load TF_IDF matrix computed previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF_IDF = load_pkl('tf_idf.pkl')\n",
    "classes = load_json('data/courses.txt')\n",
    "terms = load_pkl('terms.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity built previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(di, dj):#compute closeness between a topic and a document\n",
    "    score= np.dot(di, dj) / (np.linalg.norm(di) * np.linalg.norm(dj))# Frobenius norm byt default\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U shape: (11819, 300)\n",
      "S shape: (300,)\n",
      "V_T shape: (300, 854)\n"
     ]
    }
   ],
   "source": [
    "U, S, V_T = svds(TF_IDF, k=300, which='LM')\n",
    "\n",
    "print('U shape:', U.shape)\n",
    "print('S shape:', S.shape)\n",
    "print('V_T shape:', V_T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) According to the Dimensionality Reduction lecture:  \n",
    "* The rows of U describe how each term is related to each underlying concept. A large entry (i,j) indicates that term i is strongly related to concept j.\n",
    "* The columns of V_T describe how each class is related to each underlying concept. A large entry (i,j) indicates that concept i is strongly related to class j.\n",
    "* The roots of S describe the strength of each concept. A large entry (i,i) indicates that concept i is \"strong\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Top eigenvalues roots are located at the end of S\n",
    "top_20_eigenvalues_sqrt = S[::-1][:20]\n",
    "top_20_eigenvalues = [e*e for e in top_20_eigenvalues_sqrt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125034.54771043283, 50329.233321973268, 45116.877815600696, 42257.958891422379, 37633.456079130032, 37113.735957742443, 36008.276425117074, 35220.610036424769, 34494.550609889076, 33433.925382265923, 30772.715117247084, 30289.483195605, 29468.024971463365, 28477.490802826716, 27238.952476757793, 26488.2531148747, 26117.669567240573, 25319.194356977066, 25106.691697178565, 24865.841939481787]\n"
     ]
    }
   ],
   "source": [
    "print(top_20_eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvalues are correctly orderer by decreasing order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to understand better what types of courses are offered on the\n",
    "campus. To do so, we use LSI to extract some topics from the corpus of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  -1 :\n",
      "['phenomena5', 'microinstabilities4', 'magnetohydrodynam', 'plasmas3', 'aspectsglp', 'aspectsmarket', 'aspectsregulatori', 'aspectslega', 'aspectsstructurefinanci', 'edmt']\n",
      "['De- and re-regulation of Network Industries', 'Plasma Diagnostics in Basic Plasma Physics Devices and Tokamaks: from Principles to Practice', 'Additive Combinatorics', 'Multidisciplinary organization of medtechs/biotechs', 'Medicinal chemistry', 'Project 1 (EDIC)', 'Project 2 (EDIC)', 'Field Research Project A', 'Field Research Project B', 'Training Rotation (EDNE)']\n",
      "\n",
      "Topic  -2 :\n",
      "['asset', 'option', 'stochast', 'arbitrag', 'financ', 'financi', 'market', 'portfolio', 'price', 'risk']\n",
      "['Martingales in financial mathematics', 'Advanced topics in financial econometrics', 'Investments', 'Advanced derivatives', 'Stochastic calculus II', 'Financial econometrics', 'Stochastic calculus I', 'Risk and energy', 'Derivatives', 'Quantitative methods in finance']\n",
      "\n",
      "Topic  -3 :\n",
      "['excurs', 'form', 'design', 'week', 'report', 'urban', 'studio', 'project', 'architectur', 'wast']\n",
      "['Théorie et critique du projet MA1 (Gugger)', 'Théorie et critique du projet MA2 (Geers)', 'Théorie et critique du projet MA1 (Geers)', 'Lab immersion academic (outside EPFL) A', 'Lab immersion academic (outside EPFL) B', 'Théorie et critique du projet MA2 (Huang)', 'Lab immersion in industry A', 'Lab immersion in industry B', 'Théorie et critique du projet MA1 (Huang)', 'Solid waste engineering']\n",
      "\n",
      "Topic  -4 :\n",
      "['pollut', 'chemic', 'risk', 'water', 'municip', 'recycl', 'treatment', 'excurs', 'solid', 'wast']\n",
      "['Derivatives', 'Risk and energy', 'Eco-friendly production and process intensification', 'Quantitative methods in finance', 'Water and wastewater treatment', 'Sanitary engineering in developing countries', 'Environment chemical and biological technology', 'Applied wastewater engineering', 'Recycling of materials', 'Solid waste engineering']\n",
      "\n",
      "Topic  -5 :\n",
      "['lab', 'obtain', 'imag', 'sv', 'laboratori', 'ssv', 'host', 'report', 'laser', 'optic']\n",
      "['Biomicroscopy I', 'Image optics', 'Biomicroscopy II', 'Optics laboratories I', 'Biomedical optics', 'Photomedicine', 'Lab immersion academic (outside EPFL) A', 'Lab immersion academic (outside EPFL) B', 'Lab immersion in industry A', 'Lab immersion in industry B']\n",
      "\n",
      "Topic  -6 :\n",
      "['kinet', 'thermodynam', 'seismic', 'biolog', 'reaction', 'molecular', 'steel', 'chemic', 'cell', 'protein']\n",
      "['Lab immersion academic (outside EPFL) B', 'Lab immersion academic (outside EPFL) A', 'Stem cell biology and technology', 'Symmetry and Conservation in the Cell', 'Lab immersion in industry A', 'Biochemical engineering', 'Lab immersion in industry B', 'Molecular and cellular biophysic I', 'Molecular and cellular biophysic II', 'Advanced steel design']\n",
      "\n",
      "Topic  -7 :\n",
      "['stabil', 'frame', 'column', 'brace', 'optic', 'week', 'wast', 'seismic', 'speech', 'steel']\n",
      "['Localization and Navigation Methods', 'Non linear analysis of structures', 'Digital Speech and Audio Coding', 'Hardware systems modeling I', 'Fundamentals in Systems Engineering', 'Structural stability', 'Automatic speech processing', 'Solid waste engineering', 'Speech processing', 'Advanced steel design']\n",
      "\n",
      "Topic  -8 :\n",
      "['load', 'mrf', 'optic', 'risk', 'frame', 'column', 'brace', 'week', 'seismic', 'steel']\n",
      "['Lab immersion in industry B', 'Non linear analysis of structures', 'Théorie et critique du projet MA1 (Geers)', 'Risk and energy', '2D Layered Materials: Synthesis, Properties and Applications', 'Fracture of materials', 'Fracture Mechanics and Fatigue of Structures', 'Quantitative methods in finance', 'Structural stability', 'Advanced steel design']\n",
      "\n",
      "Topic  -9 :\n",
      "['electr', 'system', 'consequ', 'interfac', 'lab', 'ch', 'robot', 'sensor', 'biosens', '§']\n",
      "['Printed systems and large area manufacturing', 'Localization and Navigation Methods', 'Solid waste engineering', 'Robotics practicals', 'Design of Ultra-low Power Wearable Wireless Systems', 'Lab immersion academic (outside EPFL) B', 'Lab immersion academic (outside EPFL) A', 'Lab immersion in industry A', 'Lab immersion in industry B', 'Fundamentals of biosensors and electronic biochips']\n",
      "\n",
      "Topic  -10 :\n",
      "['materi', 'sensor', 'host', 'report', 'circuit', 'lab', 'electron', 'devic', 'robot', 'print']\n",
      "['Advanced MEMS', 'Design of Ultra-low Power Wearable Wireless Systems', 'Robotics practicals', 'Lab immersion academic (outside EPFL) B', 'Lab immersion academic (outside EPFL) A', 'Printed systems and large area manufacturing', 'Lab immersion in industry A', '2D Layered Materials: Synthesis, Properties and Applications', 'Lab immersion in industry B', 'Soft Microsystems Processing and Devices']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Top 10 terms per topic\n",
    "for topic in range(-1,-11,-1):\n",
    "    top_10_terms = [terms[t] for t in np.argsort(U[:,topic])[-10:]]\n",
    "    top_10_documents = [classes[d]['name'] for d in np.argsort(V_T[topic])[-10:]]\n",
    "    print('Topic ', topic,':')\n",
    "    print(top_10_terms)\n",
    "    print(top_10_documents)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We retrieved the top 10 topics ad a combination of of 10 terms and 10 document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can label the topics as following:  \n",
    "\n",
    "    1) Organization and projects in medical technologies  \n",
    "    2) Financial engineering  \n",
    "    3) Architecture  \n",
    "    4) Environmental engineering  \n",
    "    5) Applied microscopic medical sciences  \n",
    "    6) Molecular and cellular biophysics  \n",
    "    7) Systems modeling and natural language processing  \n",
    "    8) Risk management  \n",
    "    9) Applied robotics  \n",
    "    10)Electrical engineering  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will Implement a search function using LSI concept-space, and search for \"markov chains\" and\n",
    "\"facebook\". We aim at comparing vith Vector Space results computed previsouly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtain a diagonal matrix from vector S\n",
    "S_diag = np.diag(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_d_sim(query):\n",
    "    sim = np.zeros(len(classes))\n",
    "    term_U = np.zeros(300)\n",
    "    for term in query.split(\" \"):\n",
    "        \n",
    "        term_i = terms.index(term)\n",
    "        term_U += U[term_i]\n",
    "        \n",
    "    for i in range(len(classes)):\n",
    "        class_V_T = V_T[:,i]\n",
    "        d = np.dot(S_diag, class_V_T)\n",
    "        #num = np.dot(term_U, d)\n",
    "        #denom = np.linalg.norm(term_U) * np.linalg.norm(d)\n",
    "        #quotient = num / denom\n",
    "        q=cosine_similarity(term_U, d)\n",
    "        sim[i] += q\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSI_search(query):\n",
    "    sim = t_d_sim(query)\n",
    "    top_5 = np.argsort(sim)[::-1][:5]\n",
    "    for course_i in top_5:\n",
    "        print('Course: ',classes[course_i]['name'],',', ' Similarity: ', sim[course_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) As expected LSI performs better than VSM. This improvement comes from the fact that LSI relies on underlying/latent topics whereas VSM implements naive term frequency comparison. Therefore for a rare term such as \"facebook\" we get better recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course:  Computational Social Media ,  Similarity:  0.914629726075\n",
      "Course:  Social media ,  Similarity:  0.56961813888\n",
      "Course:  Studio MA2 (Escher et GuneWardena) ,  Similarity:  0.196441545312\n",
      "Course:  Human computer interaction ,  Similarity:  0.179784450763\n",
      "Course:  Transport phenomena II ,  Similarity:  0.177257241069\n"
     ]
    }
   ],
   "source": [
    "LSI_search('facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course:  Applied stochastic processes ,  Similarity:  0.779779129885\n",
      "Course:  Applied probability & stochastic processes ,  Similarity:  0.768744936584\n",
      "Course:  Markov chains and algorithmic applications ,  Similarity:  0.640434513617\n",
      "Course:  Supply chain management ,  Similarity:  0.541455248869\n",
      "Course:  Mathematical models in supply chain management ,  Similarity:  0.500342638133\n"
     ]
    }
   ],
   "source": [
    "LSI_search('markov chain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed this time 'facebook' is included into social media topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we resort to cosine similarity, i.e. we compute the cosine similarity of the column from V_T corresponding to Internet Analytics with each course/topic mapping column of V_T."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify IX class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IX_id = [i for (i, c) in enumerate(classes) if c['courseId'] == \"COM-308\"][0]\n",
    "IX_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look for courses similar to ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  0  :   Internet analytics\n",
      "Top  1  :   Distributed information systems\n",
      "Top  2  :   A Network Tour of Data Science\n",
      "Top  3  :   Financial big data\n",
      "Top  4  :   Networks out of control\n",
      "Top  5  :   Analytic algorithms\n"
     ]
    }
   ],
   "source": [
    "IX_sim = np.apply_along_axis(cosine_similarity, 0, V_T, V_T[:,IX_id])\n",
    "top_5 = np.argsort(IX_sim)[::-1][0:6]\n",
    "for i, c_i in enumerate(top_5):\n",
    "    print('Top ',i,' :',' ',classes[c_i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We notice that the five topics outputed are coherent and can be great advise to take similar courses\n",
    "next semester."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
